{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bschreck/miniconda3/envs/py3default/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils_instacart as utils\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dldb import DLDB\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data\n",
    "\n",
    "\n",
    "\n",
    "The data is partitioned into chunks based on `user_id`, and loaded into the Featuretools Entityset format. See [the original demo](https://github.com/Featuretools/predict_next_purchase) for more explananation about how the data is partitioned and the Entityset is formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = utils.load_entityset('partitioned_data/part_0/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Baseline Input Data\n",
    "\n",
    "We load in the data into an EntitySet first, in the same way we do for the DFS case. Then, we merge all the tables together to form a single CSV. Note that the first step of creating the EntitySet is not necessary, but is done here because the `load_entityset` function takes care of a lot of the formatting of the data. Instead, you can just load in the raw data, format it, and merge.\n",
    "\n",
    "We make sure to cutoff the data at the cutoff time, and only use 60 days of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_time = pd.Timestamp('March 1, 2015')\n",
    "training_window = pd.Timedelta(\"60 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftens_denormalized = utils.denormalize_entityset(es, cutoff_time, training_window)\n",
    "ftens_denormalized.sort_index(inplace=True)\n",
    "# Since we will never have the same order_id or order_product_id in the test set, we can't learn much from them\n",
    "ftens_denormalized.drop(['order_id', 'order_product_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>reordered</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>order_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2015-01-01 08:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>Soda</td>\n",
       "      <td>77</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 08:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>Organic Unsweetened Vanilla Almond Milk</td>\n",
       "      <td>91</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 08:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>Original Beef Jerky</td>\n",
       "      <td>23</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 08:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>Aged White Cheddar Popcorn</td>\n",
       "      <td>23</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 08:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>XL Pick-A-Size Paper Towel Rolls</td>\n",
       "      <td>54</td>\n",
       "      <td>household</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             reordered  \\\n",
       "user_id order_time                       \n",
       "1       2015-01-01 08:00:00          0   \n",
       "        2015-01-01 08:00:00          0   \n",
       "        2015-01-01 08:00:00          0   \n",
       "        2015-01-01 08:00:00          0   \n",
       "        2015-01-01 08:00:00          0   \n",
       "\n",
       "                                                        product_name  \\\n",
       "user_id order_time                                                     \n",
       "1       2015-01-01 08:00:00                                     Soda   \n",
       "        2015-01-01 08:00:00  Organic Unsweetened Vanilla Almond Milk   \n",
       "        2015-01-01 08:00:00                      Original Beef Jerky   \n",
       "        2015-01-01 08:00:00               Aged White Cheddar Popcorn   \n",
       "        2015-01-01 08:00:00         XL Pick-A-Size Paper Towel Rolls   \n",
       "\n",
       "                             aisle_id  department  \n",
       "user_id order_time                                 \n",
       "1       2015-01-01 08:00:00        77   beverages  \n",
       "        2015-01-01 08:00:00        91  dairy eggs  \n",
       "        2015-01-01 08:00:00        23      snacks  \n",
       "        2015-01-01 08:00:00        23      snacks  \n",
       "        2015-01-01 08:00:00        54   household  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftens_denormalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct labels\n",
    "\n",
    "This utility function picks out a window of time, and finds which users bought bananas. Again, more explanation in [the original demo](https://github.com/Featuretools/predict_next_purchase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_times = utils.make_labels(es,\n",
    "                                product_name=\"Banana\",\n",
    "                                cutoff_time=cutoff_time,\n",
    "                                prediction_window=pd.Timedelta(\"28d\"),\n",
    "                                training_window=training_window)\n",
    "labels = label_times.set_index('user_id').sort_index()['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DLDB with desired hyperparameters\n",
    "\n",
    "In this example, we use 2 fairly small [LSTM](https://keras.io/layers/recurrent/) layers and 2 feed-forward layers (called \"Dense layers\" in Keras/Tensor Flow terminology). DLDB has an extremely simple API, and exposes a large number of hyperparameters, so is amenable to hyperparameter optimization algorithms.\n",
    "\n",
    "Each categorical feature will be mapped to a 12-dimensional embedding, with a maximum of 20 unique categorical values (the top 20 most frequent values will be chosen, and the rest will be converted to a single token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model = DLDB(\n",
    "    regression=False,\n",
    "    classes=[False, True],\n",
    "    recurrent_layer_sizes=(32, 32),\n",
    "    dense_layer_sizes=(32, 16),\n",
    "    dropout_fraction=0.2,\n",
    "    recurrent_dropout_fraction=0.2,\n",
    "    categorical_embedding_size=12,\n",
    "    categorical_max_vocab=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model and test using cross-validation\n",
    "\n",
    "We use a `batch_size` of 128 (for each gradient update step) and train over 3 passes of the dataset (epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits=20\n",
    "splitter = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we tell DL-DB explicitly what feature names are categorical (all of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6694\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 5s 681ms/step - loss: 0.6263\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 5s 662ms/step - loss: 0.5998\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 5s 655ms/step - loss: 0.5849\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 5s 644ms/step - loss: 0.5655\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 5s 665ms/step - loss: 0.5389\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5946428571428571\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.6841\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6612\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 6s 888ms/step - loss: 0.6436\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 6s 833ms/step - loss: 0.6196\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 6s 819ms/step - loss: 0.6000\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 6s 808ms/step - loss: 0.5899\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.41785714285714287\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.6740\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 568ms/step - loss: 0.6368\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 4s 592ms/step - loss: 0.6090\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 4s 585ms/step - loss: 0.5926\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 571ms/step - loss: 0.5757\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 4s 578ms/step - loss: 0.5501\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.3214285714285714\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6769\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 624ms/step - loss: 0.6401\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 5s 644ms/step - loss: 0.6076\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 4s 613ms/step - loss: 0.5884\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 642ms/step - loss: 0.5724\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 5s 655ms/step - loss: 0.5635\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.49464285714285716\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6745\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 608ms/step - loss: 0.6379\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 4s 639ms/step - loss: 0.6169\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 0.5879\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 606ms/step - loss: 0.5635\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 4s 619ms/step - loss: 0.5423\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.6017857142857143\n",
      "Epoch 1/6\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6753Epoch 1/6\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6752\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 0.6386\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 4s 622ms/step - loss: 0.6081\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 0.5825\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 616ms/step - loss: 0.5583\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 4s 633ms/step - loss: 0.5284\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5107142857142857\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6798\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 642ms/step - loss: 0.6484\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 4s 621ms/step - loss: 0.6273\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 5s 651ms/step - loss: 0.6036\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 623ms/step - loss: 0.5805\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 4s 627ms/step - loss: 0.5605\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.6178571428571429\n",
      "Epoch 1/6\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6759Epoch 1/6\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6761\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 630ms/step - loss: 0.6357\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 4s 637ms/step - loss: 0.6076\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 4s 638ms/step - loss: 0.5886\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 623ms/step - loss: 0.5671\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 4s 632ms/step - loss: 0.5445\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5482142857142858\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6785\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 0.6473\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 5s 648ms/step - loss: 0.6227\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 4s 599ms/step - loss: 0.6025\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 0.5858\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 4s 617ms/step - loss: 0.5567\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5142857142857142\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6804\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 633ms/step - loss: 0.6523\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 5s 644ms/step - loss: 0.6302\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 4s 639ms/step - loss: 0.6102\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 626ms/step - loss: 0.5997\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 4s 605ms/step - loss: 0.5759\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.36326530612244895\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6708\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 636ms/step - loss: 0.6220\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 4s 634ms/step - loss: 0.5879\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 4s 623ms/step - loss: 0.5714\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 634ms/step - loss: 0.5390\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 4s 626ms/step - loss: 0.5031\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.7469387755102042\n",
      "Epoch 1/6\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6752\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6752\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 5s 643ms/step - loss: 0.6376\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 6s 900ms/step - loss: 0.6094\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 7s 936ms/step - loss: 0.5862\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 6s 817ms/step - loss: 0.5639\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 5s 778ms/step - loss: 0.5375\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.18487394957983194\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.6669\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 4s 598ms/step - loss: 0.6253\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 5s 655ms/step - loss: 0.5943\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 5s 649ms/step - loss: 0.5703\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 5s 656ms/step - loss: 0.5425\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 5s 664ms/step - loss: 0.5089\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.46638655462184875\n",
      "Epoch 1/6\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6652\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.6656\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 5s 699ms/step - loss: 0.6245\n",
      "Epoch 3/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 671ms/step - loss: 0.5896\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 5s 654ms/step - loss: 0.5632\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 4s 634ms/step - loss: 0.5427\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 5s 709ms/step - loss: 0.5080\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.7773109243697479\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.6741\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 5s 758ms/step - loss: 0.6322\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 5s 762ms/step - loss: 0.6040\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.5783\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 5s 780ms/step - loss: 0.5614\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 6s 799ms/step - loss: 0.5328\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.7373949579831933\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.6766\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 6s 790ms/step - loss: 0.6384\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 6s 791ms/step - loss: 0.6165\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 5s 766ms/step - loss: 0.5914\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 5s 742ms/step - loss: 0.5675\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 5s 780ms/step - loss: 0.5353\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.8067226890756303\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 17s 2s/step - loss: 0.6744\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 5s 739ms/step - loss: 0.6301\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 5s 777ms/step - loss: 0.6025\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 5s 780ms/step - loss: 0.5853\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 5s 751ms/step - loss: 0.5606\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 5s 722ms/step - loss: 0.5244\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5840336134453782\n",
      "Epoch 1/6\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.6735\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 6s 797ms/step - loss: 0.6322\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 7s 942ms/step - loss: 0.6050\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.5801\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.5501\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 7s 993ms/step - loss: 0.5290\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5924369747899159\n",
      "Epoch 1/6\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 0.6695\n",
      "7/7 [==============================] - 18s 3s/step - loss: 0.6678\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6245\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6052\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 6s 811ms/step - loss: 0.5832\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 6s 857ms/step - loss: 0.5613\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.5408\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.6974789915966386\n",
      "Epoch 1/6\n",
      "6/7 [========================>.....] - ETA: 3s - loss: 0.6756Epoch 1/6\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.6761\n",
      "Epoch 2/6\n",
      "7/7 [==============================] - 6s 919ms/step - loss: 0.6391\n",
      "Epoch 3/6\n",
      "7/7 [==============================] - 6s 815ms/step - loss: 0.6158\n",
      "Epoch 4/6\n",
      "7/7 [==============================] - 5s 662ms/step - loss: 0.5861\n",
      "Epoch 5/6\n",
      "7/7 [==============================] - 5s 665ms/step - loss: 0.5630\n",
      "Epoch 6/6\n",
      "7/7 [==============================] - 6s 800ms/step - loss: 0.5352\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5252100840336134\n",
      "AUC 0.56 +/- 0.07\n"
     ]
    }
   ],
   "source": [
    "cv_score = []\n",
    "\n",
    "for i, train_test_index in enumerate(splitter.split(labels, labels)):\n",
    "    train_labels = labels.iloc[train_test_index[0]]\n",
    "    test_labels = labels.iloc[train_test_index[1]]\n",
    "    train_ftens = ftens_denormalized.reset_index('order_time', drop=True).loc[train_labels.index, :]\n",
    "    test_ftens = ftens_denormalized.reset_index('order_time', drop=True).loc[test_labels.index, :]\n",
    "\n",
    "    dl_model.fit(\n",
    "        train_ftens, train_labels,\n",
    "        categorical_feature_names=train_ftens.columns,\n",
    "        # Provide this many samples to the network at a time\n",
    "        batch_size=128,\n",
    "        epochs=6,\n",
    "        # Set this to number of cores\n",
    "        workers=8,\n",
    "        use_multiprocessing=True,\n",
    "        shuffle=False,)\n",
    "    \n",
    "    predictions = dl_model.predict(test_ftens)\n",
    "    score = roc_auc_score(test_labels, predictions)\n",
    "    print(\"cv score: \", score)\n",
    "    cv_score.append(score)\n",
    "\n",
    "mean_score = np.mean(cv_score)\n",
    "stderr = 2 * (np.std(cv_score) / np.sqrt(n_splits))\n",
    "\n",
    "print(\"AUC %.2f +/- %.2f\" % (mean_score, stderr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
