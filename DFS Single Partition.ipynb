{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bschreck/miniconda3/envs/py3default/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.1.18'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import featuretools as ft\n",
    "from featuretools.primitives import Day, Weekend, Weekday, Percentile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils_instacart as utils\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dldb import DLDB, tdfs, make_temporal_cutoffs\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "ft.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = utils.load_entityset('partitioned_data/part_0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_time = pd.Timestamp('March 1, 2015')\n",
    "training_window = ft.Timedelta(\"60 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_times = utils.make_labels(es,\n",
    "                                product_name=\"Banana\",\n",
    "                                cutoff_time=cutoff_time,\n",
    "                                prediction_window=ft.Timedelta(\"4 weeks\"),\n",
    "                                training_window=training_window)\n",
    "labels = label_times.set_index('user_id').sort_index()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features: 349it [00:00, 5482.85it/s]\n",
      "Progress: 100%|██████████| 21/21 [07:15<00:00, 20.75s/cutoff time]\n"
     ]
    }
   ],
   "source": [
    "# Note: increasing max_depth from 2 to 3 increases auc from .7 to .9\n",
    "trans_primitives = [Day, Weekend, Weekday, Percentile]\n",
    "fm, fl = tdfs(entityset=es,\n",
    "              target_entity=\"users\",\n",
    "              cutoffs=label_times,\n",
    "              trans_primitives=trans_primitives,\n",
    "              training_window=training_window,\n",
    "              max_depth=3,\n",
    "              window_size='3d',\n",
    "              start=cutoff_time - training_window,\n",
    "              verbose=True)\n",
    "\n",
    "fm = fm.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features: 349it [00:00, 6151.74it/s]\n"
     ]
    }
   ],
   "source": [
    "trans_primitives = [Day, Weekend, Weekday, Percentile]\n",
    "fl = tdfs(entityset=es,\n",
    "              target_entity=\"users\",\n",
    "              cutoffs=label_times,\n",
    "              trans_primitives=trans_primitives,\n",
    "              training_window=training_window,\n",
    "              max_depth=3,\n",
    "              window_size='3d',\n",
    "              start=cutoff_time - training_window,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(fl, \"fl.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.to_csv(\"fm_part_0.csv\")\n",
    "labels.to_frame().to_csv(\"label_times_part_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model = DLDB(\n",
    "    regression=False,\n",
    "    classes=[False, True],\n",
    "    recurrent_layer_sizes=(32, 32),\n",
    "    dense_layer_sizes=(32, 32),\n",
    "    dropout_fraction=0.2,\n",
    "    recurrent_dropout_fraction=0.1,\n",
    "    categorical_embedding_size=20,\n",
    "    categorical_max_vocab=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is *slightly* cheating because we give it all the categorical values ahead of time\n",
    "# It most likely won't make a difference, and this step takes some time\n",
    "# Feel free to move it inside of the cross-validation for loop\n",
    "dl_model.compile(fm, fl=fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model and test using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming input matrix into numeric sequences\n",
      "Fitting Keras model\n",
      "Train on 678 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "678/678 [==============================] - 4s 7ms/step - loss: 0.5049 - val_loss: 0.4065\n",
      "Epoch 2/100\n",
      "678/678 [==============================] - 1s 2ms/step - loss: 0.4565 - val_loss: 0.3492\n",
      "Epoch 3/100\n",
      "678/678 [==============================] - 1s 2ms/step - loss: 0.4136 - val_loss: 0.3300\n",
      "Epoch 4/100\n",
      "678/678 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.3593\n",
      "Transforming input matrix into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "Transforming input matrix into numeric sequences\n",
      "Fitting Keras model\n",
      "Train on 679 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "679/679 [==============================] - 1s 1ms/step - loss: 0.3735 - val_loss: 0.3577\n",
      "Epoch 2/100\n",
      "679/679 [==============================] - 1s 1ms/step - loss: 0.3553 - val_loss: 0.3824\n",
      "Transforming input matrix into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "Transforming input matrix into numeric sequences\n",
      "Fitting Keras model\n",
      "Train on 679 samples, validate on 76 samples\n",
      "Epoch 1/100\n",
      "679/679 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.4019\n",
      "Epoch 2/100\n",
      "679/679 [==============================] - 1s 1ms/step - loss: 0.3566 - val_loss: 0.3366\n",
      "Epoch 3/100\n",
      "679/679 [==============================] - 1s 1ms/step - loss: 0.3504 - val_loss: 0.3544\n",
      "Transforming input matrix into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "AUC 0.80 +/- 0.06\n"
     ]
    }
   ],
   "source": [
    "cv_score = []\n",
    "n_splits = 3\n",
    "test_frac = 0.1\n",
    "# Use 10% of data as testing set, but only run 3 rounds of cross-validation\n",
    "# (because they take a while)\n",
    "splitter = StratifiedKFold(n_splits=int(1/test_frac), shuffle=True)\n",
    "\n",
    "for i, train_test_index in enumerate(splitter.split(labels, labels)):\n",
    "    train_labels = labels.iloc[train_test_index[0]]\n",
    "    test_labels = labels.iloc[train_test_index[1]]\n",
    "    train_fm = fm.loc[(train_labels.index, slice(None)), :]\n",
    "    test_fm = fm.loc[(test_labels.index, slice(None)), :]\n",
    "\n",
    "    dl_model.fit(\n",
    "        train_fm, train_labels,\n",
    "        # Provide 32 samples to the network at a time\n",
    "        batch_size=32,\n",
    "        # Train on at most 100 passes of the dataset (epochs)\n",
    "        epochs=100,\n",
    "        # After each epoch, test on a held out 10% validation set\n",
    "        validation_split=0.1,\n",
    "        # If no improvement, stop training\n",
    "        callbacks=[EarlyStopping()])\n",
    "    \n",
    "    predictions = dl_model.predict(test_fm)\n",
    "    cv_score.append(roc_auc_score(test_labels, predictions))\n",
    "    if i == n_splits - 1:\n",
    "        break\n",
    "mean_score = np.mean(cv_score)\n",
    "stderr = 2 * (np.std(cv_score) / np.sqrt(n_splits))\n",
    "\n",
    "print(\"AUC %.2f +/- %.2f\" % (mean_score, stderr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
