{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bschreck/miniconda3/envs/py3default/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.1.20'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import featuretools as ft\n",
    "from featuretools.primitives import Day, Weekend, Weekday, Percentile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils_instacart as utils\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from dldb import DLDB\n",
    "import os\n",
    "ft.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data\n",
    "\n",
    "The data is partitioned into chunks based on `user_id`, and loaded into the Featuretools Entityset format. See [the original demo](https://github.com/Featuretools/predict_next_purchase) for more explanation about how the data is partitioned and the Entityset is formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = utils.load_entityset('partitioned_data/part_0/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construct labels\n",
    "\n",
    "This utility function picks out a window of time, and finds which users bought bananas. Again, more explanation in [the original demo](https://github.com/Featuretools/predict_next_purchase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_time = pd.Timestamp('March 1, 2015')\n",
    "training_window = \"60 days\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_times = utils.make_labels(es,\n",
    "                                product_name=\"Banana\",\n",
    "                                cutoff_time=cutoff_time,\n",
    "                                prediction_window=pd.Timedelta(\"28 days\"),\n",
    "                                training_window=pd.Timedelta(training_window))\n",
    "labels = label_times.set_index('user_id').sort_index()['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create time-stamped feature matrix using DFS\n",
    "\n",
    "Here is where things start to get interesting. We use the `make_temporal_cutoffs` function in Featuretools to produce a feature matrix with several rows per user. It works by adding additional cutoff times in the past to each `(user_id, cutoff_time)` provided in `label_times`.\n",
    "\n",
    "This function has a few different ways of selecting these additional cutoff times. Here, we provide `window_size='3d'` and `start=cutoff_time - training_window`, which will go back in time in increments of 3 days until 60 days before the cutoff time of March 1st. This produces a sequence of 20 cutoff times per user.\n",
    "\n",
    "We could have also specified `num_windows=20` and `window_size=3d` to produce the same result.\n",
    "\n",
    "The rest of the arguments are standard DFS arguments. For an overview of DFS, check out the [Featuretools documentation](https://docs.featuretools.com/automated_feature_engineering/afe.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 78 features\n",
      "Elapsed: 05:13 | Remaining: 00:00 | Progress: 100%|██████████| Calculated: 11/11 chunks\n"
     ]
    }
   ],
   "source": [
    "trans_primitives = [Day, Weekend, Weekday, Percentile]\n",
    "temporal_cutoffs = ft.make_temporal_cutoffs(instance_ids=label_times['user_id'],\n",
    "                                            cutoffs=label_times['time'],\n",
    "                                            window_size='3d',\n",
    "                                            start=[cutoff_time - pd.Timedelta(training_window)] * len(label_times))\n",
    "# Note that ft.dfs expects either an Featuretools Timedelta object or a string, \n",
    "# not a Pandas Timedelta object\n",
    "ftens, fl = ft.dfs(entityset=es,\n",
    "                target_entity=\"users\",\n",
    "                cutoff_time=temporal_cutoffs,\n",
    "                trans_primitives=trans_primitives,\n",
    "                training_window=training_window,\n",
    "                max_depth=2,\n",
    "                verbose=True)\n",
    "\n",
    "ftens = ftens.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can save/restore our work without having to recompute feature matrix\n",
    "#ftens.to_csv('ftens_part_0.csv')\n",
    "#ftens = pd.read_csv('ftens_part_0.csv', parse_dates=['time'], index_col=['user_id', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft.save_features(fl, 'fl_part_0.p')\n",
    "#fl = ft.load_features('fl_part_0.p', es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DLDB with desired hyperparameters\n",
    "\n",
    "In this example, we use 2 fairly small [LSTM](https://keras.io/layers/recurrent/) layers and 2 feed-forward layers (called \"Dense layers\" in Keras/Tensor Flow terminology). DLDB has an extremely simple API, and exposes a large number of hyperparameters, so is amenable to hyperparameter optimization algorithms.\n",
    "\n",
    "Each categorical feature will be mapped to a 12-dimensional embedding, with a maximum of 20 unique categorical values (the top 20 most frequent values will be chosen, and the rest will be converted to a single token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model = DLDB(\n",
    "    regression=False,\n",
    "    classes=[False, True],\n",
    "    recurrent_layer_sizes=(32, 32),\n",
    "    dense_layer_sizes=(32, 16),\n",
    "    dropout_fraction=0.2,\n",
    "    recurrent_dropout_fraction=0.2,\n",
    "    categorical_embedding_size=12,\n",
    "    categorical_max_vocab=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model and test using cross-validation\n",
    "\n",
    "We use a `batch_size` of 128 (for each gradient update step) and train over 3 passes of the dataset (epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits=20\n",
    "splitter = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7/7 [==============================] - 6s 889ms/step - loss: 0.6797\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 2s 221ms/step - loss: 0.6354\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.6011\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.49642857142857144\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.6854\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.6674\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 2s 276ms/step - loss: 0.6551\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.375\n",
      "Epoch 1/3\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6815Epoch 1/3\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6812\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 112ms/step - loss: 0.6574\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 0.6368\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.4285714285714286\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6806\n",
      "Epoch 2/3\n",
      "\n",
      "7/7 [==============================] - 1s 172ms/step - loss: 0.6536\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 0.6358\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.1875\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.6750\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.6379\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 125ms/step - loss: 0.6163\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.4125\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6827\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6644\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.6470\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.3803571428571429\n",
      "Epoch 1/3\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.6848\n",
      "7/7 [==============================] - 6s 815ms/step - loss: 0.6855\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.6655\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 174ms/step - loss: 0.6465\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.3607142857142857\n",
      "Epoch 1/3\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6880Epoch 1/3\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.6878\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 0.6692\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.6549\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.4392857142857143\n",
      "Epoch 1/3\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6820\n",
      "7/7 [==============================] - 7s 975ms/step - loss: 0.6813\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.6595\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 162ms/step - loss: 0.6384\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5265306122448979\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 6s 885ms/step - loss: 0.6827\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 124ms/step - loss: 0.6618\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.6398\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.4857142857142857\n",
      "Epoch 1/3\n",
      "6/7 [========================>.....] - ETA: 2s - loss: 0.6768Epoch 1/3\n",
      "7/7 [==============================] - 15s 2s/step - loss: 0.6770\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 128ms/step - loss: 0.6510\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 0.6254\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.3224489795918367\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6756\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 113ms/step - loss: 0.6424\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.6183\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.23949579831932774\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 12s 2s/step - loss: 0.6822\n",
      "Epoch 2/3\n",
      "\n",
      "7/7 [==============================] - 1s 129ms/step - loss: 0.6544\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.6309\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.39285714285714285\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 18s 3s/step - loss: 0.6879\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 122ms/step - loss: 0.6740\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 121ms/step - loss: 0.6627\n",
      "Transforming input tensor into numeric sequences\n",
      "\n",
      "Epoch 3/3Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.5714285714285714\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6781\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.6530\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 104ms/step - loss: 0.6300\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.43277310924369744\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 8s 1s/step - loss: 0.6794\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 0.6496\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 0.6292\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.37184873949579833\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 10s 1s/step - loss: 0.6788\n",
      "Epoch 2/3\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 0.6494\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.6229\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.4915966386554622\n",
      "Epoch 1/3\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6801Epoch 1/3\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6802\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 109ms/step - loss: 0.6503\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.6248\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.33613445378151263\n",
      "Epoch 1/3\n",
      "6/7 [========================>.....] - ETA: 1s - loss: 0.6772Epoch 1/3\n",
      "7/7 [==============================] - 9s 1s/step - loss: 0.6761\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 116ms/step - loss: 0.6399\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 80ms/step - loss: 0.6087\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.634453781512605\n",
      "Epoch 1/3\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.6743\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 0.6413\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 0.6122\n",
      "Transforming input tensor into numeric sequences\n",
      "Predicting using Keras model\n",
      "Transforming outputs\n",
      "cv score:  0.46218487394957986\n",
      "AUC 0.42 +/- 0.05\n"
     ]
    }
   ],
   "source": [
    "cv_score = []\n",
    "\n",
    "for train_test_index in splitter.split(labels, labels):\n",
    "    train_labels = labels.iloc[train_test_index[0]]\n",
    "    test_labels = labels.iloc[train_test_index[1]]\n",
    "    train_ftens = ftens.loc[train_labels.index, :]\n",
    "    test_ftens = ftens.loc[test_labels.index, :]\n",
    "\n",
    "    dl_model.fit(\n",
    "        train_ftens, train_labels,\n",
    "        fl=fl,\n",
    "        # Provide this many samples to the network at a time\n",
    "        batch_size=128,\n",
    "        epochs=3,\n",
    "        # Set this to number of cores\n",
    "        workers=8,\n",
    "        use_multiprocessing=True,\n",
    "        shuffle=False,)\n",
    "    \n",
    "    predictions = dl_model.predict(test_ftens)\n",
    "    score = roc_auc_score(test_labels, predictions)\n",
    "    print(\"cv score: \", score)\n",
    "    cv_score.append(score)\n",
    "mean_score = np.mean(cv_score)\n",
    "stderr = 2 * (np.std(cv_score) / np.sqrt(n_splits))\n",
    "\n",
    "print(\"AUC %.2f +/- %.2f\" % (mean_score, stderr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
